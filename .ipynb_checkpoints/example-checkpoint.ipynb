{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keypoint Detection\n",
    "\n",
    "First, the reading and video lecture associated with this section:\n",
    "Szeliski 4.1.  [Mubarak Shah's Lecture on Harris Corner detection](https://www.youtube.com/watch?v=S4mMhuLHrsQ&list=UUlOghZ_xkI1km31IeoY-9Bw).\n",
    "\n",
    "Now that we have the capabililties in hand to run convolution operations on images, producing outputs that have strong responses to a variety of features (edges, for example), we are in a position to start looking for features in the image that might be good to match.  As it turns out, edges aren't good features to match at all, because they have a tendency to look similar all along the edge.  Instead, it's better to try and match corners.  This is the reasoning behind most keypoint detectors, and most panorama stitching applications work in this way.   \n",
    "\n",
    "What defines a corner?  A corner is an object where there are big changes to the image no matter which direction we look.  We can reason about whether a given image patch exhibits this property by looking at a so-called *autocorrelation function*:\n",
    "$$\n",
    "E_{ac}(\\Delta \\mathbf{u}) = \\sum_{i} w_i [I(\\mathbf{u}_i + \\Delta \\mathbf{u}) - I(\\mathbf{u}_i)]^2\n",
    "$$\n",
    "where $I$ is image intensity, $\\Delta \\mathbf{u}$ is a vector of position change, $w$ is an arbitrary kernel, and the summation is over a neighborhood of pixels.  This expression is a little unwieldly.  We can simplify it by approximating the perturbation term with a first order Taylor Series:\n",
    "$$\n",
    "E_{ac}(\\Delta \\mathbf{u}) = \\sum_{i} w_i [I(\\mathbf{u}_i) + \\nabla I(\\mathbf{u}_i) \\Delta \\mathbf{u} - I(\\mathbf{u}_i)]^2.\n",
    "$$\n",
    "The two intensity terms cancel, and we're left with an expression that only depends on the gradient of the image (which we already know how to calculate).\n",
    "$$\n",
    "E_{ac}(\\Delta \\mathbf{u}) = \\sum_{i} w_i [\\nabla I(\\mathbf{u}_i) \\Delta \\mathbf{u}]^2 = \\Delta \\mathbf{u}^T \\mathbf{A} \\Delta \\mathbf{u},\n",
    "$$\n",
    "where we can define the (pixel-wise) auto-correlation matrix:\n",
    "$$\n",
    "A = \\begin{bmatrix} \\sum_i w_i \\, \\partial_u I_i^2 & \\sum_i w_i \\;\\partial_u I_i \\;\\partial_v I_i \\\\\n",
    "                    \\sum_i w_i \\; \\partial_u I_i \\; \\partial_v I_i & \\sum_i w_i \\; \\partial_v I_i^2 \\end{bmatrix}\n",
    "                                $$\n",
    "or more concisely as \n",
    "$$\n",
    "A = w \\star \\begin{bmatrix} \\partial_u I^2 & \\partial_u I \\partial_v I \\\\\n",
    "                            \\partial_u I \\partial_v I & \\partial_v I^2 \\end{bmatrix}\n",
    "$$                            \n",
    "This matrix has all the information about corners that we need in it.  Specifically, it's telling us the way that auto-correlation changes as we move in different directions.  \n",
    "\n",
    "So given this information, what do we need to know to determine if a particular spot is a corner?  We can determine this by finding the eigenvalues of this matrix, which essentially tells us how much the autocorrelation is changing in the direction of the biggest change (the biggest eigenvalue, which we'll call $\\lambda_0$), and also in the direction orthogonal to it (the second eigenvalue $\\lambda_1$).  There are three cases that correspond to three possible situations.  First, it could be the case that both $\\lambda_0$ and $\\lambda_1$ are both very small.  This typically implies that there is not much contrast, and that there is not a corner, or even an edge.  The second case is when $\\lambda_0>>\\lambda_1$.  This implies that the image is changing alot in one direction, but not much at all in the other direction, which corresponds to an edge.  Finally we have the situation where $\\lambda_0$ and $\\lambda_1$ are both large and of similar magnitude.  This implies a corner.  The so-called Harris response \n",
    "$$h(\\mathbf u) = \\frac{\\lambda_0 \\lambda_1}{\\lambda_0 + \\lambda_1}$$ \n",
    "is designed to produce a large value whenever this latter condition is satisfied, and thus will be big for every point that is a corner.  \n",
    "\n",
    "Note that it would be inefficient to actually form the matrix $A$ and solve for eigenvalues at every point on an image.  Instead we can recognize that both the numerator and the denominator in $h(\\mathbf{u}$ are matrix invariants: $\\lambda_0 \\lambda_1 = \\mathrm{Det}(\\mathbf{A})$ and $\\lambda_0 + \\lambda_1 = \\mathrm{Tr}(\\mathbf{A})$.  Thus we get some pretty easy discrete formulas: \n",
    "$$\n",
    "H = [I_{uu} \\circ I_{vv} - I_{uv}\\circ I_{uv}] \\oslash [I_{uu} + I_{vv}],\n",
    "$$\n",
    "where $H$ is the pixel-wise Harris response and \n",
    "$$\n",
    "I_{uu} = w \\star [I_u \\circ I_u]\n",
    "$$\n",
    "$$\n",
    "I_{vv} = w \\star [I_v \\circ I_v]\n",
    "$$\n",
    "$$\n",
    "I_{uv} = w \\star [I_u \\circ I_v]\n",
    "$$\n",
    "and $\\circ$ and $\\oslash$ are elementwise multiplication and division (you will sometimes hear these operations referred to as the Hadamard product and Hadamard division). \n",
    "\n",
    "Lastly, we need to make a choice regarding our discrete convolution kernel $w$.  Empirical studies have shown that a good choice is to use a Gaussian kernel with $\\sigma=2$.  This effectively smooths the computation of the gradient over several pixels, so that small scale noise in the image does not produce spurious corners.\n",
    "\n",
    "**Write a function that computes the Harris response over an arbitrary image.  Test this function on two images: first, on the image of a chess-board that is included in this repo.  Second, test it on an image of your choosing.  Does your code produce the expected result of large Harris response at features that could qualitatively be described as corners?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "I = plt.imread('chessboard.png')\n",
    "I2 = plt.imread('chessboard.png')\n",
    "I3 = plt.imread('chessboard.png')\n",
    "I4 = plt.imread('chessboard.png')\n",
    "I5 = plt.imread('chessboard.png')\n",
    "I6 = plt.imread('chessboard.png')\n",
    "plt.imshow(I,cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, what we want to do with this is to create a set of discrete points $(u,v)$ that we can match between images.  These points should correspond to local maxima in the Harris response.  **Given a Harris response matrix, write a function that extracts local maxima, and outputs an array of their coordinates**.  This can be done relatively easily via *non-linear* filtering: loop through all of the pixels in the Harris response, and determine if that pixel is the largest in its neighborhood.  If so, then it's a local maximum.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.misc\n",
    "import math as mt\n",
    "import imageio as im\n",
    "\n",
    "def convolve(g,h, I_gray_copy): # h is kernel, g is the image\n",
    "   \n",
    "    x,y = h.shape\n",
    "    xl = int(x/2)\n",
    "    yl = int(y/2)\n",
    "    for i in range(xl,len(g[:,1])-xl):\n",
    "        for j in range(yl, len(g[i,:])-yl):\n",
    "\n",
    "            f = g[i-xl:i+(xl+1), j-yl:j+(yl+1)] #FIXME\n",
    "            \n",
    "            total = h*f\n",
    "            I_gray_copy[i][j] = sum(sum(total)) + .0000001\n",
    "            \n",
    "    return I_gray_copy\n",
    "           \n",
    "def gauss_kernal(size, var):\n",
    "    kernel = np.zeros(shape=(size,size))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            kernel[i][j] = mt.exp( -((i - (size-1)/2)**2 + (j - (size-1)/2)**2 )/(2*var*var))\n",
    "\n",
    "    kernel = kernel / kernel.sum()\n",
    "    return kernel           \n",
    "\n",
    "def harris_response(img, gmean = 5,var =2):\n",
    "\tsobel = np.array([[-1,0,1],[-2,0,2],[-1,0,1]]) \n",
    "\tgauss = gauss_kernal(gmean,var)\n",
    "#calculate the harris response using sobel operator and gaussian kernel\n",
    "\n",
    "\tIu = convolve(img,sobel,I2)\n",
    "\tIv = convolve(img,sobel.transpose(), I3)\n",
    "\n",
    "\tIuu = convolve(Iu*Iu,gauss, I4)\n",
    "\tIvv = convolve(Iv*Iv,gauss, I5)\n",
    "\tIuv = convolve(Iu*Iv,gauss, I6)\n",
    "\n",
    "\tH = (Iuv*Ivv - Iuv*Iuv)/(Iuu + Ivv)\n",
    "\n",
    "\treturn H\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = harris_response(I,gmean = 5,var=2)\n",
    "\n",
    "\n",
    "plt.imshow(H,cmap=plt.cm.gray)\n",
    "#.imshow(I,cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmaxima (H,threshold):\n",
    "    maxima = []\n",
    "    x,y = H.shape\n",
    "    for i in range(1,x-1):\n",
    "        for j in range(1,y-1):\n",
    "            if H[i,j] > threshold :\n",
    "                continue\n",
    "            \n",
    "            if(    H[i,j] > H[i+1,j]   and  H[i,j] > H[i-1,j] \n",
    "               and H[i,j] > H[i,j-1]   and  H[i,j] > H[i,j+1]\n",
    "               and H[i,j] > H[i+1,j-1] and  H[i,j] > H[i+1,j+1]\n",
    "               and H[i,j] > H[i-1,j-1] and  H[i,j] > H[i-1,j+1]):\n",
    "                \n",
    "                maxima.append([i,j,H[i][j]])\n",
    "   \n",
    "    print(maxima)\n",
    "    \n",
    "    return maxima\n",
    "\n",
    "def get_local_maxima(H):\n",
    "    localMax = []\n",
    "    \n",
    "    for i in range(1,len(H)-1):\n",
    "        for j in range(1,len(H[i])-1):\n",
    "            neighborhood = H[i-1:i+2, j-1:j+2]\n",
    "            max_val = max(max(x) for x in neighborhood)\n",
    "            if(max_val == H[i][j] and max_val!= 0):\n",
    "                localMax.append([i,j,H[i][j],np.inf])\n",
    "    return localMax\n",
    "\n",
    "\n",
    "\n",
    "#local_max = get_local_maxima(H)\n",
    "#print(local_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonmaxsup(H,n=100,c=.9):\n",
    "    \n",
    "    mindistance = []\n",
    "    threshold = np.mean(H) + np.std(H)\n",
    "    maxima = getmaxima(H,threshold)\n",
    "    x = 0\n",
    "    y = 1\n",
    "    z = 2\n",
    "    for row in maxima:\n",
    "        min = np.inf\n",
    "        for row1 in maxima:\n",
    "            dist = np.sqrt((row[x]-row1[x])**2 + (row[y]-row1[y])**2 )\n",
    "            if row[z] < c*row1[z] and dist > 0 and dist < min:\n",
    "                min = dist\n",
    "                xmin = row1[x]\n",
    "                ymin = row1[y]\n",
    "\n",
    "        mindistance.append([row1[x],row1[y],min])\n",
    "\n",
    "    mindistance.sort(key=lambda x:x[2])\n",
    "    return mindistance[:n]\n",
    "\n",
    "\n",
    "nms = nonmaxsup(H)\n",
    "\n",
    "print(len(nms))\n",
    "'''c = .9\n",
    "def distance(x1,y1,x2,y2):\n",
    "    return np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "\n",
    "num_keypts = len(local_max)\n",
    "\n",
    "x = 0\n",
    "\n",
    "while(x < num_keypts):\n",
    "    for j in range(num_keypts):\n",
    "        if(j != x):\n",
    "            if(local_max[j][2]*c > local_max[x][2]):\n",
    "                if(distance(local_max[j][0],local_max[j][1], local_max[x][0], local_max[x][1]) < local_max[x][3]):\n",
    "                    local_max[x][3] = distance(local_max[j][0],local_max[j][1], local_max[x][0], local_max[x][1])\n",
    "    x+=1\n",
    "\n",
    "print(\"Finished\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def sort_dist(val):\n",
    "    return val[3]\n",
    "\n",
    "local_max.sort(reverse=True, key=sort_dist)'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
